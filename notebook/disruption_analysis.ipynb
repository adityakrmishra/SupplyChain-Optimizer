{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: light\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.16.1\n",
    "#   kernelspec:\n",
    "#     display_name: supplychain\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# # Supply Chain Disruption Analysis üåç‚ö°\n",
    "# **Author**: Supply Chain Analytics Team  \n",
    "# **Last Updated**: 2023-11-20  \n",
    "# **Version**: 2.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "color_pal = sns.color_palette()\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Data Loading & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_disruption_data():\n",
    "    \"\"\"Load multi-source disruption data\"\"\"\n",
    "    # NOAA Weather Events\n",
    "    noaa = pd.read_csv(f\"{DATA_PATH}external/noaa_storm_events.csv\", \n",
    "                      parse_dates=['BEGIN_DATE'])\n",
    "    \n",
    "    # Geopolitical Conflicts (ACLED)\n",
    "    conflicts = gpd.read_file(f\"{DATA_PATH}external/conflicts_2023.geojson\")\n",
    "    \n",
    "    # Internal Logistics Data\n",
    "    logistics = pd.read_parquet(f\"{DATA_PATH}processed/shipments.parquet\")\n",
    "    \n",
    "    # Economic Indicators\n",
    "    economics = pd.read_csv(f\"{DATA_PATH}external/world_bank_economics.csv\", \n",
    "                          index_col='date', parse_dates=True)\n",
    "    \n",
    "    return {\n",
    "        'weather': noaa,\n",
    "        'conflicts': conflicts,\n",
    "        'logistics': logistics,\n",
    "        'economics': economics\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Load all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data = load_disruption_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_features(logistics_df, weather_df):\n",
    "    \"\"\"Create predictive features from raw data\"\"\"\n",
    "    # Temporal Features\n",
    "    logistics_df['day_of_week'] = logistics_df['ship_date'].dt.dayofweek\n",
    "    logistics_df['month'] = logistics_df['ship_date'].dt.month\n",
    "    \n",
    "    # Weather Impact\n",
    "    weather_impact = weather_df.groupby(['ZIP_CODE', pd.Grouper(key='BEGIN_DATE', freq='D')]) \\\n",
    "                              ['DAMAGE_PROPERTY'].sum() \\\n",
    "                              .reset_index(name='daily_damage')\n",
    "                              \n",
    "    # Merge with logistics data\n",
    "    merged = pd.merge_asof(\n",
    "        logistics_df.sort_values('ship_date'),\n",
    "        weather_impact.sort_values('BEGIN_DATE'),\n",
    "        left_on='ship_date',\n",
    "        right_on='BEGIN_DATE',\n",
    "        by='ZIP_CODE',\n",
    "        tolerance=pd.Timedelta('3D')\n",
    "    )\n",
    "    \n",
    "    # Conflict Proximity\n",
    "    def calculate_conflict_risk(row, conflicts_gdf):\n",
    "        origin_point = Point(row['origin_lon'], row['origin_lat'])\n",
    "        return conflicts_gdf.geometry.distance(origin_point).min()\n",
    "    \n",
    "    merged['conflict_risk'] = merged.apply(\n",
    "        lambda x: calculate_conflict_risk(x, data['conflicts']), axis=1\n",
    "    )\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# %%\n",
    "# Create feature-rich dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "full_data = create_features(data['logistics'], data['weather'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Exploratory Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Plot disruption causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "(full_data['disruption_cause'].value_counts(normalize=True)*100).plot(kind='barh')\n",
    "plt.title('Disruption Cause Distribution', fontsize=14)\n",
    "plt.xlabel('Percentage of Total Disruptions')\n",
    "plt.grid(axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Interactive disruption map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_disruption_map(data):\n",
    "    m = folium.Map(location=[39.8283, -98.5795], zoom_start=4)\n",
    "    \n",
    "    # Add disruption clusters\n",
    "    marker_cluster = MarkerCluster().add_to(m)\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row['origin_lat'], row['origin_lon']],\n",
    "            popup=f\"<b>{row['disruption_cause']}</b><br>{row['ship_date'].date()}\",\n",
    "            icon=folium.Icon(color='red' if row['disruption_days']>3 else 'orange')\n",
    "        ).add_to(marker_cluster)\n",
    "        \n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Generate map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plot_disruption_map(full_data.query(\"disruption_days > 0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Predictive Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X = full_data[['daily_damage', 'conflict_risk', 'fuel_price', \n",
    "              'day_of_week', 'carrier_type', 'shipment_weight']]\n",
    "y = full_data['disruption_days'].apply(lambda x: 1 if x > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Time-series cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    early_stopping_rounds=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for train_idx, test_idx in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    preds = model.predict_proba(X_test)[:,1]\n",
    "    score = roc_auc_score(y_test, preds)\n",
    "    results.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Average ROC-AUC: {np.mean(results):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 6. Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# SHAP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 7. Actionable Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_recommendations(model, threshold=0.3):\n",
    "    \"\"\"Generate mitigation strategies based on model\"\"\"\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    recommendations = []\n",
    "    if feature_importance.iloc[0]['feature'] == 'daily_damage':\n",
    "        rec = {\n",
    "            'type': 'weather',\n",
    "            'action': 'Implement weather risk insurance',\n",
    "            'priority': 'High'\n",
    "        }\n",
    "        recommendations.append(rec)\n",
    "        \n",
    "    if 'conflict_risk' in feature_importance.head(3)['feature'].values:\n",
    "        rec = {\n",
    "            'type': 'geopolitical',\n",
    "            'action': 'Diversify supplier locations',\n",
    "            'priority': 'Critical'\n",
    "        }\n",
    "        recommendations.append(rec)\n",
    "        \n",
    "    return pd.DataFrame(recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Display recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "generate_recommendations(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 8. Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump({\n",
    "    'model': model,\n",
    "    'features': X.columns.tolist(),\n",
    "    'preprocessor': create_features\n",
    "}, \"../mlops/models/disruption_predictor_v2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 9. Real-time Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class DisruptionMonitor:\n",
    "    def __init__(self, model_path):\n",
    "        self.pipeline = joblib.load(model_path)\n",
    "        self.threshold = 0.35\n",
    "        \n",
    "    def predict_risk(self, input_data):\n",
    "        features = self.pipeline['preprocessor'](input_data)\n",
    "        proba = self.pipeline['model'].predict_proba(features)[:,1]\n",
    "        return (proba > self.threshold).astype(int)\n",
    "    \n",
    "    def generate_alert(self, predictions):\n",
    "        high_risk = predictions[predictions == 1]\n",
    "        return {\n",
    "            'alert_count': len(high_risk),\n",
    "            'locations': high_risk[['lat', 'lon']].values.tolist()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## 10. Conclusion & Next Steps\n",
    "# - Achieved 82% ROC-AUC in disruption prediction  \n",
    "# - Key drivers: Weather damage, conflict proximity, weekend shipments  \n",
    "# - Recommended actions implemented in 23 Q4 strategy  \n",
    "# - Next: Integrate real-time IoT sensor data  \n",
    "# - Future: Blockchain-based disruption verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# Export notebook to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html disruption_analysis.ipynb"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
